Your friend Richard would like to build a classifier to predict whether a high school student's final grade in a language subject is among the better half of the class. For each high school student, he already knows how he/she performed in the last semester (binary target variable: YES if the student was among the better half of the class and NO if the student was among the worse half of the class). \\

Understandably, no classifier will be able to predict very well with little information. Richard therefore came up with a few potential features he could use. Before going through the hassle of getting data for these potential features, cleaning it, etc., Richard turns to you. He would like you to rank these potential features based on how much you expect them to increase classifier performance. Using your ranking, Richard will acquire data for your highest ranked feature first, followed by the second, etc. \\

All of Richard's feature ideas are binary, this means that they can either be true or false. Note, that numeric variables can easily be transformed into binary variables by binning them. For example, the variable "student age" can be binned into the binary variables "younger than 15", "between 15 and 18 years", "older than 18" at some information loss. In that case, we treat each bin as an individual feature, since some bins might be more valuable to Richard's classifier than others. Also note that categorical variables can easily be transformed into binary variables through dummy extraction. In this case, we also treat all arising dummies as separate features. \\

Please help Richard and rank the list of potential features by relevancy. The element on the top of the list should promise the largest improvement to the classifier, the second should see the second highest improvement in classifier performance, etc...
